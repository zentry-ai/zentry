{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from zentry import Memory\n",
    "from datetime import datetime\n",
    "import anthropic\n",
    "\n",
    "# Set up environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"  # needed for embedding model\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"your_anthropic_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportChatbot:\n",
    "    def __init__(self):\n",
    "        # Initialize zentry with Anthropic's Claude\n",
    "        self.config = {\n",
    "            \"llm\": {\n",
    "                \"provider\": \"anthropic\",\n",
    "                \"config\": {\n",
    "                    \"model\": \"claude-3-5-sonnet-latest\",\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"max_tokens\": 2000,\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "        self.client = anthropic.Client(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "        self.memory = Memory.from_config(self.config)\n",
    "\n",
    "        # Define support context\n",
    "        self.system_context = \"\"\"\n",
    "        You are a helpful customer support agent. Use the following guidelines:\n",
    "        - Be polite and professional\n",
    "        - Show empathy for customer issues\n",
    "        - Reference past interactions when relevant\n",
    "        - Maintain consistent information across conversations\n",
    "        - If you're unsure about something, ask for clarification\n",
    "        - Keep track of open issues and follow-ups\n",
    "        \"\"\"\n",
    "\n",
    "    def store_customer_interaction(self, user_id: str, message: str, response: str, metadata: Dict = None):\n",
    "        \"\"\"Store customer interaction in memory.\"\"\"\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "\n",
    "        # Add timestamp to metadata\n",
    "        metadata[\"timestamp\"] = datetime.now().isoformat()\n",
    "\n",
    "        # Format conversation for storage\n",
    "        conversation = [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": response}]\n",
    "\n",
    "        # Store in zentry\n",
    "        self.memory.add(conversation, user_id=user_id, metadata=metadata)\n",
    "\n",
    "    def get_relevant_history(self, user_id: str, query: str) -> List[Dict]:\n",
    "        \"\"\"Retrieve relevant past interactions.\"\"\"\n",
    "        return self.memory.search(\n",
    "            query=query,\n",
    "            user_id=user_id,\n",
    "            limit=5,  # Adjust based on needs\n",
    "        )\n",
    "\n",
    "    def handle_customer_query(self, user_id: str, query: str) -> str:\n",
    "        \"\"\"Process customer query with context from past interactions.\"\"\"\n",
    "\n",
    "        # Get relevant past interactions\n",
    "        relevant_history = self.get_relevant_history(user_id, query)\n",
    "\n",
    "        # Build context from relevant history\n",
    "        context = \"Previous relevant interactions:\\n\"\n",
    "        for memory in relevant_history:\n",
    "            context += f\"Customer: {memory['memory']}\\n\"\n",
    "            context += f\"Support: {memory['memory']}\\n\"\n",
    "            context += \"---\\n\"\n",
    "\n",
    "        # Prepare prompt with context and current query\n",
    "        prompt = f\"\"\"\n",
    "        {self.system_context}\n",
    "\n",
    "        {context}\n",
    "\n",
    "        Current customer query: {query}\n",
    "\n",
    "        Provide a helpful response that takes into account any relevant past interactions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate response using Claude\n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-latest\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=2000,\n",
    "            temperature=0.1,\n",
    "        )\n",
    "\n",
    "        # Store interaction\n",
    "        self.store_customer_interaction(\n",
    "            user_id=user_id, message=query, response=response, metadata={\"type\": \"support_query\"}\n",
    "        )\n",
    "\n",
    "        return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = SupportChatbot()\n",
    "user_id = \"customer_bot\"\n",
    "print(\"Welcome to Customer Support! Type 'exit' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    query = input()\n",
    "    print(\"Customer:\", query)\n",
    "\n",
    "    # Check if user wants to exit\n",
    "    if query.lower() == \"exit\":\n",
    "        print(\"Thank you for using our support service. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Handle the query and print the response\n",
    "    response = chatbot.handle_customer_query(user_id, query)\n",
    "    print(\"Support:\", response, \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
